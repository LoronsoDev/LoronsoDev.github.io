[{"content":"\u0026ldquo;Everything should be made as simple as possible, but not simpler\u0026rdquo;\n","date":"1 January 1970","permalink":"/","section":"","summary":"\u0026ldquo;Everything should be made as simple as possible, but not simpler\u0026rdquo;","title":""},{"content":"","date":"1 January 1970","permalink":"/languages/blueprints/","section":"Languages","summary":"","title":"Blueprints"},{"content":"\rWhat is a flipbook? # When we use high-quality, hard to simulate effects in videogames, most of what you see is usually \u0026ldquo;faked\u0026rdquo; through the use of flipbooks. Through the use of a single texture, several frames of the simulation are laid next to each other, ready to be extracted by the developer once it\u0026rsquo;s inside the game engine. Once ready, each frame is shown in the order they were simulated and laid in the flipbook, creating the illusion of being simulated in real-time. Due to the nature of this technique, this means that FX created using flipbooks are completely flat (2D). Game developer usually fake this by creating a billboard with this texture, which is nothing more than a texture that is constantly looking at the camera plane.\nexample of a flipbook But isn\u0026rsquo;t that extremely performance intensive? # It is indeed, and it\u0026rsquo;s not only costly on the render side: it\u0026rsquo;s also a problem with storage. High quality simulations tend to have lots of data, needing textures with a very high resolution in order to look convincing. Through this post we\u0026rsquo;ll see a common technique of optimization, its results, and how to do it.\nOptimizing our flipbooks # The most obvious way to optimize our flipbooks is through two ways: reducing the resolution of the flipbook and using the least textures possible. But this comes with a huge quality drawback, as any VFX based in flipbook usage has to share the resolution of the texture between all of the frames. So, for a 2048x2048 flipbook with 64 frames, laid in a square of 8 frames per row and column (8x8), we would only have 2048/8 = 256 pixels available for each frame. We can just go and add more resolution, but that would only lead us to a bigger problem.\nThis is one the problems that Mederic, former VFX Tech Director of Skull \u0026amp; Bones, found while trying to have convincing explosions. I\u0026rsquo;m basing this post on his explanation of this problem on Real-Time VFX forums.\nMotion-based vectors # So what do we do then? We can\u0026rsquo;t just go ahead and delete frames randomly. Even though it would work, and we would achieve a higher resolution per frame, the result would just be a choppy mess that would hardly be identifiable as an explosion.\nThis is when the magic happens: interpolation\nWe can create another flipbook with the data of the motion in that pixel, or in other words: a flipbook storing the changes from one frame to the next. So\u0026hellip; if we have this, we can just interpolate from one frame, to the next one, in the direction stored here, right? ABSOLUTELY!\nMotion vector textures usually only pack data for the X and Y positions. This means that, for a texture, it only occupies two channels, usually the RG channels of a RGB/RGBA texture. This gives it its green-yellowish color.\nMotion vector example For the same explosion:\nFrames without motion-based vectors Frames with motion-based vectors Using motion-based vectors we managed to go down from a 11x11 grid holding data for 121 frames, to a 6x6 grid with only 32 frames. This means close to double the resolution per frame.\nFor another flipbook with 64 frames, we can see an example of the result here:\nIngame view of 120 linear vs 64 interpolated You might notice that 64 frames also looks darker. This leads us to the next section!\nBaked lighting for flipbooks: TLRB textures # By definition, a flipbook by itself would be impossible to lit correctly in a game scene, as after all it\u0026rsquo;s only a plane with some color applied, and there isn\u0026rsquo;t any volumetric smoke or simulation to lit.\nTo combat this, we introduce lighting maps. Lighting maps are just the same frames we had before, but with baked lighting data in it, rendered in the simulation software. For this, we render each frame once with a directional light pointing at it from different directions. This can be an infinite number of directions, but for performance purposes, I\u0026rsquo;m keeping it at 4 directions, as those are the channels we typycally use in a texture (R,G,B,A).\nThe original post by Mederic at VFX forums uses lights positioned at the top, left, right and bottom of the simulation volume. JangaFX, makers of the Embergen real-time simulation software also followed the same formula. So we\u0026rsquo;re not gonna be less. For commodity purposes, we\u0026rsquo;re gonna call this the TLRB texture from now on, according to the respective position of each direction in the texture. This is also how it\u0026rsquo;s called inside Embergen.\nExample of a TLRB texture Top Left Right Bottom Red channel Green channel Blue channel Alpha channel Emissive data # In order to achieve a better customization of our flipbook inside the game engine, it\u0026rsquo;s better to not cache any data that isn\u0026rsquo;t of the same type, or similar, together. This means that, for the explosion used as an example in this post, we want to differentiate between the explosion itself and the smoke it generates. This opens our way to change different parameters of the explosion once cached and in the game engine.\nWe can apply a blackbody based color ramp to this to give it any temperature inside the game engine. This gives us control of its color and intensity based on real-world properties, as well as the ability to change its hue, if we want to change its color from a natural one to a fantasy one (for example, if we want to represent magic).\nBlackbody radiation ramps courtesy of Blender and Wikipedia Personalized explosion with different value of temperature and hue For this, we simply export the emissive data from our simulation. Both Embergen and Houdini support this, being relatively easy to export. More on this later on this post.\nTransparency data # Flipbook textures usually need more information on what\u0026rsquo;s transparent, and to what extent. This is what makes parts of our smoke see-through where there is less density. For this, we also need to export the transparency data, usually called alpha. For this we only need a single channel, as the texture only holds data for what\u0026rsquo;s visible or not.\nAlpha channel example Overview # So we are aware now of all the parts of our textures. The only part left is assembling them together. Let\u0026rsquo;s see what we have:\nA motion-based vector texture consisting on X and Y movements, occupying the R and G channels. A TLRB texture with 4 channels, one for each light. A channel for emissives in the simulation. A channel for transparency. This totals up to 8 channels, or two RGBA textures\u0026hellip; What a coincidence! It\u0026rsquo;s almost as if we had thought of this on purpose.\nWe can arrange this in any way we want, but as we\u0026rsquo;re aiming for Unreal Engine, the most useful way of packing it is as follows:\nTexture 1\nChannel Data R Motion Vectors X G Motion Vectors Y B Emissives A Transparency/Alpha Texture 2 - TLRB texture\nChannel Data R Top lighting G Left lighting B Right lighting A Bottom lighting Example Texture 1 Example Texture 2 Exporting this data # I will go through how to create these textures in the most commonly used fluid simulation software for game development at the moment - Embergen and Houdini. We will start with Embergen as the incredible, beautiful, godly, sigma team at JangaFX has prepared a tremendously easy way to export this kind of textures. Houdini is not too hard either, it\u0026rsquo;s just rougher to work with, but SideFX has also prepared some things for this kind of exports.\nEmbergen # Both of the textures presented are supported natively by Embergen. However, we do have to modify it to an extent in order to only use two textures.\nEmbergen export settings to achieve Texture1 and Texture 2 presented in this post As of Embergen v1.0.5 (August, 2023), Embergen has a bug with how their TLR capture lays the data on the channels, as they\u0026rsquo;ve accidentally flipped Top and Right, making it RLT instead of TLR. The image above fixes this by flipping them back, shown in Six Point 1 (TLR).\nIt is possible that this might be fixed when you\u0026rsquo;re following this post. Do not blindly follow the above image before checking.\nYou can check the state of this issue by checking the channels first or at their Discord bug tracker.\nEmbergen will create an output file for each capture. This is not a big problem, as we can just ignore them. I suggest naming them first to know which output files are the ones you want once exported.\nHoudini # Although we can create a relatively complex setup to achieve this, SideFX has us covered with their Labs node Labs Flipbook Textures.\nHoudini calls this MDC (Multidirectional Contributions), but it is the exact same procedure. It does have some differences in their implementation though, which will lead to a slightly different result when we\u0026rsquo;re rendering using this method. We will also explore some ways to avoid this.\nThis node renders the explosion using the viewport, so you don\u0026rsquo;t need to setup any renderers like Mantra or similar. It does need a pyrobakevolume node on our volume setup in our /obj/ network. So first of all, we need to make sure that we have one ready.\nAn example explosion setup with a Pyro Bake Volume node ready Once ready, back in our /out/ network, we can deploy a Labs Flipbook Textures node and set it up accordingly. We will only need to render some passes, so even if you can choose to render what you want, I find it easier to just remove what we\u0026rsquo;re not using from the setup. We also need to change how the node is compositing our textures.\nMain setup Export setup Using the default MDC has a slight problem though: Houdini doesn\u0026rsquo;t lay their lights how we\u0026rsquo;re expecting. Their method has been designed to contain more lights, so their lights are setup in different direction, going around the volume in small increments. This means that our lights will all be slightly moved, as there are no lights in a purely top/left/right/bottom direction, which might be noticeable ingame if we\u0026rsquo;re using Embergen generated flipbooks along with Houdini. Even if we aren\u0026rsquo;t, the results won\u0026rsquo;t be as consistent as they could be, as the lighting in the volume won\u0026rsquo;t be 100% accurate. We can still use this and it will look alright inside Unreal, as it will interpolate between the other lights and not be very noticeable, but we will fix this editing the Labs Flipbook Node by right clicking on it and pressing Allow editing of contents in locked node.\nAllow editing of contents in locked node Once unlocked, we will be able to get into the node. What we are going to do is basically changing the light directions in order to achieve the result we want. This will allow us to render the textures easily and have only one material back in Unreal for Embergen or Houdini generated textures.\nInside the Texture Flipbook Labs node What we want to edit is inside the Object Networks mdc_a and mdc_b. The settings should go as follows:\nnetwork name x rot y rot z rot mdc_a mdc0 (red) -90 0 0 mdc_a mdc1 (green) 0 -90 0 mdc_a mdc2 (blue) 0 90 0 \u0026ndash; \u0026ndash; \u0026ndash; \u0026ndash; \u0026ndash; mdc_b mdc0 (red) 90 0 0 The directions in the table are set accordingly to the TLRB paradigm we\u0026rsquo;ve set through this post. Red is top, green is left, etc. The red light in mdc_b will end up in the alpha channel of the final texture.\nAll lights should be parented with the camera, as it comes by default. Keep the color as it is. Remove the spare light in mdc_b and keep only the red one.\nmdc_a mdc_b Now we can press Render in our Labs Texture Flipbook node, wait for the render and then export the textures from the export tab in the Labs Texture Flipbook node settings.\nUsing this inside Unreal Engine 5 # There is an infinite number of ways of dealing with this inside Unreal, but there are a few keypoints:\nUsing 4 light points, you need to estimate the result for the front and back lighting yourself. For motion vectors, the easiest way of dealing with motion vectors is by using Unreal Engine\u0026rsquo;s Flipbook Motion Vectors node. You can try implementing it yourself but this works great. You\u0026rsquo;ll need to estimate where the light is in relation to the flipbook render. Completely explaining how to do this inside Unreal would take ages and it wouldn\u0026rsquo;t be as easy to understand as seeing it yourself, so here is a material that takes into account the textures we\u0026rsquo;ve just created. You can navigate it freely from here. You can copy and paste this into a material inside Unreal, as if it was the Unreal editor, and it will work without problems. I suggest that you check it out on fullscreen or at blueprintUE, where you will also be able to copy it easily.\nThis material will react to the directional light set in the scene by lighting up the flipbook render according to the baked lights rendered in Embergen/Houdini. It will also interpolate between the frames using the motion based texture we created.\nOverview # Feel free to drop a comment down below if you need any assistance or just want to say hi! I really hope this helped you. I\u0026rsquo;ve tried it to keep the performance and memory overhead to the bare minimum, but this technique has infinite ways of implementing it, depending on your necessities. The good thing about this is that we can achieve greater levels of detail in the flipbook by assigning more pixels per frame, as well as having the adequate parameters to reuse the explosion if needed. This is useful for fire simulations, for example, as they can be reused as smoke sprites or clouds without the need of having another flipbook explicitly created just for it.\n","date":"1 January 1970","permalink":"/posts/explosion-fx/","section":"Posts","summary":"What is a flipbook?","title":"Creating optimized, convincing explosions for Unreal Engine 5"},{"content":"","date":"1 January 1970","permalink":"/engines/","section":"Engines","summary":"","title":"Engines"},{"content":"","date":"1 January 1970","permalink":"/languages/","section":"Languages","summary":"","title":"Languages"},{"content":"\n","date":"1 January 1970","permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":"1 January 1970","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":"1 January 1970","permalink":"/tags/tutorial/","section":"Tags","summary":"","title":"Tutorial"},{"content":"","date":"1 January 1970","permalink":"/languages/ue-materials/","section":"Languages","summary":"","title":"UE Materials"},{"content":"","date":"1 January 1970","permalink":"/engines/unreal-engine/","section":"Engines","summary":"","title":"Unreal Engine"},{"content":"","date":"1 January 1970","permalink":"/languages/c#/","section":"Languages","summary":"","title":"C#"},{"content":" This game is playable on itch.io\rTry this game!\rWhat is G!RO? # As last year students, some of my classmates and I decided to create small, addictive mobile games so we could iterate easily and test different concepts. We tried several prototypes with the idea of having only the \u0026ldquo;tapping\u0026rdquo; input available. G!RO is the result of one of those prototypes.\nIn G!RO you are in control of a spaceship that has lost one of its motors and spins endlessly while trapped in an unknown planet. Your role is to survive for as long as possible using your main weapon for movement and defense.\nMy role in G!RO # As we started testing different concepts, we needed tools to iterate fast. I was in charge of researching the most commonly used features of hypercasual games, designing and developing an in-engine tool that provided most of the implementations hypercasual-arcade games for mobile usually need, while being fully customizable. The tool is fully interchangeable between different games, supports 2D and 3D and only requires minimum configuration to work. This means: Menu functionality (responsive, provided default menus and means to customize them). Store Player selection Inventories Ads and IAPs (In-App purchases) Several minor implementations (volume buttons, basic graphical quality settings) Hard \u0026amp; soft currency Hooks menu\u0026lt;-\u0026gt;game so all the developer had to do was listen to specific events (e.g. starting the game) Saving/Loading locally (playerprefs, encrypted/unencrypted JSON) Improving gameplay feedback: Dynamically displaying current user weapon charge, limiting UI and implementing it into the game design. Screen shake Creating a procedural world different for each playthrough Implementing different biomes made by the artists Implementing different spaceship types/weapons Optimizing game world so the game could be played in low-end games Bug fixing Honorable mentions # Awarded \u0026ldquo;Most enjoyable game\u0026rdquo; @ Indie Burger Awards, hosted at BIG, formerly Fun\u0026amp;Serious Bilbao Nomination for \u0026ldquo;Best old school arcade game\u0026rdquo; @ Indie Burger Awards, hosted at BIG, formerly Fun\u0026amp;Serious Bilbao ","date":"1 January 1970","permalink":"/projects/gro/","section":"Projects","summary":"This game is playable on itch.","title":"G!RO"},{"content":"","date":"1 January 1970","permalink":"/tags/personal-project/","section":"Tags","summary":"","title":"Personal project"},{"content":"\n","date":"1 January 1970","permalink":"/projects/","section":"Projects","summary":"","title":"Projects"},{"content":"","date":"1 January 1970","permalink":"/engines/unity/","section":"Engines","summary":"","title":"Unity"},{"content":" This game is made for Pico 4 VR headsets using the OpenXR standard\rWhat is Alien Agent? # Alien Agent is a short game set in an alternate universe future, where you\u0026rsquo;re in the boots of a soldier, in a future where the army is made up of ordinary people controlling robots fighting in distant conflicts.\nMy role in Alien Agent # The whole experience has been designed \u0026amp; developed by me, using bought art assets from Sinty Studios. However, some highlights are:\nCreated a flow for iterating faster with Pico 4 headsets, as they were quite new at the moment and development tools were rough.\nDesigned the levels, minigames and the whole experience.\nImplemented diegetic menus and interfaces.\nImplemented virtual hands that reproduce the player\u0026rsquo;s hand movements by retrieving the Pico button states and animating the ingame hands accordingly.\nAdded physics support so players can interact with their environment without the need of explicitly grabbing the items.\nSupported wearables, like hats or bracelets.\nCreated custom shaders to better differentiate certain parts of the experience.\nImplemented double handed weapons and their behaviour.\nModified render pipeline so certain things could be supported, this was specially useful for 3D tutorials like arrows indicating the next steps. This modifications allowed for the custom shaders to be rendered through any object, so the user could see their next step at any moment just by looking around.\nAnimated certain parts of the experience to achieve better feedback for the end user and increase immersion.\n","date":"1 January 1970","permalink":"/projects/vr-inside-vr-adventure/","section":"Projects","summary":"This game is made for Pico 4 VR headsets using the OpenXR standard\rWhat is Alien Agent?","title":"Alien Agent"},{"content":"","date":"1 January 1970","permalink":"/tags/vr/","section":"Tags","summary":"","title":"VR"},{"content":" This game is playable on Google Play and App Store\rTry this game! Android\r- iOS\rWhat is Nadurines? # Nadurines is a minigame-based game for children. I was part of the development of one of its DLC.\nMy role in Nadurines # Developed \u0026ldquo;lights\u0026rdquo; minigame, a time management minigame where you have to avoid leaving lights on when there isn\u0026rsquo;t anyone inside.\nDeveloped \u0026ldquo;runer\u0026rdquo; minigame, where the player needs to avoid obstacles for as long as possible.\nDeveloped unique superpowers for each of the characters. Dynamic obstacle generation Dynamic difficulty (changing per time) Changed base game architecture to support the addition of several new characters, part of the DLC.\nMofified all base game minigames so they could support new player selected characters.\nImplemented soft coins that players can use to buy ingame items.\nModified bath minigame so it could fit new items.\nModified clothing minigame so all player-selectable characters can wear any kind of clothing.\nModified \u0026ldquo;plant growing\u0026rdquo; minigame so the player could use more seeds, with new kinds of trees and fruits dropping from them.\nImplemented design team\u0026rsquo;s requests throughout the game.\nCreated in-engine tool so the design team could easily implement new stories in the style of visual novel games, which was a completely new part of the game.\nHonorable mentions # Nadurines currently has a positive rating in both Android and Apple Stores +500.000 downloads ","date":"1 January 1970","permalink":"/projects/nadurines/","section":"Projects","summary":"This game is playable on Google Play and App Store\rTry this game!","title":"Nadurines"},{"content":"","date":"1 January 1970","permalink":"/tags/professional-project/","section":"Tags","summary":"","title":"Professional project"},{"content":"","date":"1 January 1970","permalink":"/languages/assimp/","section":"Languages","summary":"","title":"Assimp"},{"content":"","date":"1 January 1970","permalink":"/languages/c++/","section":"Languages","summary":"","title":"C++"},{"content":"","date":"1 January 1970","permalink":"/engines/game-engine-architecture/","section":"Engines","summary":"","title":"Game Engine Architecture"},{"content":"\rWhat is this engine? # Since I started making games, I\u0026rsquo;ve been deeply intrigued in the inner workings of more commercial engines. This was my first iteration of a game engine.\nIt supports 2D and 3D graphics using SDL2 for 2D and CPU rendering for 3D. The engine supports physics via a implementation of Box2D (2D) and Bullet Physics (3D).\nThe engine is built around an ECS (Entity-Component-System) architecture.\nLoronsoDev/GameEngine2\rSecond version of my yet-unnamed game engine. Can support 3D and 2D. Implements Bullet Physics for 3D and Box2D for 2D development. This engine is highly commented and valuable as a learning tool. It is not being worked on.\rC\u0026#43;\u0026#43; 0\r0\rWhy do I consider this project important? # This project set my stepping stone to larger projects involving graphics and general game engine programming. It sparked enough curiosity in me to continue studying code architecture, computer graphics and proper GPU APIs like OpenGL or Vulkan.\nWhy did I stop working on it? # At a point in its development, the engine needed reflection so I could translate the custom scene files into scenes that could be generated at runtime. I considered that instead of trying to implement it, I could just stop the work there, document everything clearly and use it for future reference in other engines if needed. I started working in this engine as a newbie with C++, so I feared that if I started implementing my own custom C++ reflection or any other reflection API, the engine could become so convoluted that I would no longer be able to maintain it properly. I preferred to have a working build that could be used by me or others for learning and start a new project from scratch using what I learnt while building this engine.\n","date":"1 January 1970","permalink":"/projects/engine-sdl/","section":"Projects","summary":"What is this engine?","title":"My first (unnamed) Game Engine"},{"content":"","date":"1 January 1970","permalink":"/languages/sdl2/","section":"Languages","summary":"","title":"SDL2"},{"content":" This game is playable on itch.io\rTry this game!\rWhat is GALAXY FORCES? # Galaxy Forces was a video game created for a degree assignment. It got out ouf hand for me, as I was really liking the smoothness of the gameplay, so I spent much, much longer than needed polishing it up and creating a fun product to play.\nThe game is designed to be played with joysticks, but it also supports virtual mobile joysticks and keyboard. Due to the nature of the gameplay, using keyboard is the least preferred option.\nThe goal of the game is to finish in the least amount of time possible, killing the most enemies possible throughout the play. The score system is designed to reflect it, giving more score if you go faster.\nAn obvious inspiration for this game is Starfox (Nintendo).\nMy role in GALAXY FORCES # I made all the code related parts of this project alone (gameplay, UI, tools\u0026hellip;), using Unity. All art excluding the spaceship is bought from the Unity Asset Store. The spaceship was modelled by a colleague.\nWhat am I proud of developing here? # I especially liked how the feeling turned out. I experimented a lot with feedback and FX. To give the player a good sense of speed, I spawned particles all around the camera, speeding them up when the user went faster and increased the FOV dramatically. I also experimented with postprocess in this regard, adding things like blur and chromatic aberration when going faster.\nAdding the crosshair was also a really tricky part, as representing 3D spaces in a 2D space (screen space) while also giving the user the sense of control is very tricky. I ended up drawing a virtual line from the tip of the spaceship to the usual attack length, taking that position and translating it to the screen space, drawing the crosshair there. It felt really good.\nA good challengue here was performance too, as spawning a big number of enemies, with their own logic and with the ability to spawn bullets was giving a good toll on performance. I ended up going around this by hiding all enemies that were occluded by any of the geometry or that were behind the player (dot(player, enemy) \u0026lt; 0). I also pooled all spawnable objects and enemies, so I didn\u0026rsquo;t need to allocate memory every time I needed to instantiate one of them, and also avoiding the performance hit of destroying gameobjects by only disabling and reusing them.\n","date":"1 January 1970","permalink":"/projects/galaxy-forces/","section":"Projects","summary":"This game is playable on itch.","title":"Galaxy Forces"},{"content":"","date":"1 January 1970","permalink":"/tags/ar/","section":"Tags","summary":"","title":"AR"},{"content":" This project is property of Isostopy, SL. More information can be seen on https://isostopy.com/project/pre-trip-inspection/\rWhat is PRE TRIP INSPECTION? # Pre Trip Inspection is an immersive training system for professional drivers adapted to US regulations. The solution was created “ad hoc” for the North American company Advanced Training Systems LLC (ATS), a leading company in the virtual training sector for carriers.\nThis app offers a revolutionary quick, precise and easy training system, which streamlines the training of drivers both in risk prevention and in obtaining specific certifications and licenses, allowing users to choose between training in virtual reality mode or in augmented reality according to your needs.\nMy role in PRE TRIP INSPECTION # I was part of the team as an intern.\nImplemented Vuforia\u0026rsquo;s SDK for AR viewing using AR cards.\nImplemented different modes, like \u0026ldquo;evaluation\u0026rdquo; mode, that did an exam to the user, or \u0026ldquo;practice\u0026rdquo; mode, that asked the users the same question as evaluation mode, but was infinite.\nDeveloped shaders for outlining different parts of the truck body.\nImplemented different viewing modes (buttons and swiping)\nCreated in-engine tool to add/remove questions easily.\nImplemented different camera movements so the camera didn\u0026rsquo;t clip through the truck if not necessary.\n","date":"1 January 1970","permalink":"/projects/pre-trip-inspection-us-cdl/","section":"Projects","summary":"This project is property of Isostopy, SL.","title":"Pre trip Inspection (US CDL)"},{"content":" This game is playable on itch.io\rTry this game!\rWhat is FADE? # FADE was a video game created in 4 days as part of Telefonica\u0026rsquo;s hackathon \u0026ldquo;HackForGood\u0026rdquo;. The goal of the event was to create pieces of software that could be used for the greater good, in any way.\nWe chose to create a short story based on an elderly woman suffering from Alzheimer. Our objective was to raise awareness around this issue, getting our players to play as her.\nIt\u0026rsquo;s important to note that video games for this event were strictly in the category of \u0026ldquo;serious games\u0026rdquo;, which led to us making some modifications in the way the game was handled and played.\nMy role in FADE # In this project, I got to work on: ​\nMovement\nInteractions\nAnimation integration\nPuzzle minigames\nParallax \u0026amp; depth effects\nArt integration\nHonorable mentions # 2nd prize in Telefónica/Movistar hosted hackathon \u0026ldquo;HackForGood\u0026rdquo; ","date":"1 January 1970","permalink":"/projects/fade/","section":"Projects","summary":"This game is playable on itch.","title":"FADE"},{"content":"","date":"1 January 1970","permalink":"/tags/game-jam/","section":"Tags","summary":"","title":"Game Jam"},{"content":"","date":"1 January 0001","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"1 January 0001","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":" ","date":"1 January 0001","permalink":"/resume/","section":"Loading CV...","summary":" ","title":"Loading CV..."},{"content":"","date":"1 January 0001","permalink":"/series/","section":"Series","summary":"","title":"Series"}]